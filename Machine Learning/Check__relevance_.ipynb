{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "BrhBbzxyH_Zn"
   },
   "outputs": [],
   "source": [
    "path_medical_word_list = 'wordlist.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "JDAKJ8RDPns8"
   },
   "outputs": [],
   "source": [
    "def get_medical_sector_words(pth):\n",
    "  Medical_words = []\n",
    "  with open(pth) as f:\n",
    "    Medical_words.append(f.readlines())\n",
    "  Medical_sector_words = \"\"\n",
    "  for i in Medical_words[0]:\n",
    "    Medical_sector_words  = Medical_sector_words + \" \"+(i.replace('\\n',''))\n",
    "  return Medical_sector_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "Ogxmwbf4Qbx_"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'wordlist.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/58/dnxmgvzx4_55v7cc2mb6vqdh0000gn/T/ipykernel_6474/2997847022.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mMedical_sector_words_lest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_medical_sector_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_medical_word_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/58/dnxmgvzx4_55v7cc2mb6vqdh0000gn/T/ipykernel_6474/3338649598.py\u001b[0m in \u001b[0;36mget_medical_sector_words\u001b[0;34m(pth)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_medical_sector_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mMedical_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpth\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mMedical_words\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mMedical_sector_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'wordlist.txt'"
     ]
    }
   ],
   "source": [
    "Medical_sector_words_lest = get_medical_sector_words(path_medical_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rxp9mIVjVhjl"
   },
   "outputs": [],
   "source": [
    "speech_one = '''The moving images of a film are created by photographing actual scenes with a motion-picture camera, by photographing drawings or miniature models using traditional animation techniques, by means of CGI and computer animation, or by a combination of some or all of these techniques, and other visual effects.\n",
    "Before the introduction of digital production, series of still images were recorded on a strip of chemically sensitized celluloid (photographic film stock), usually at the rate of 24 frames per second. The images are transmitted through a movie projector at the same rate as they were recorded, with a Geneva drive ensuring that each frame remains still during its short projection time. A rotating shutter causes stroboscopic intervals of darkness, but the viewer does not notice the interruptions due to flicker fusion.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "0c3ObmeYVvKY"
   },
   "outputs": [],
   "source": [
    "speech_two = '''Doctors play a pivotal role in building the society. They are the lifelines of the community.\n",
    "This term can be used very literally for the Doctors who shape culture and save those that are diseased and unhealthy. \n",
    "Doctors work hard to save the lives of patients with serious ailments. \n",
    "They act as an inspiration to society.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "u0yBIDThWHR3"
   },
   "outputs": [],
   "source": [
    "speech_three = ''' Common signs of infection include respiratory symptoms, fever, cough, \n",
    "shortness of breath and breathing difficulties. In more severe cases, \n",
    "infection can cause pneumonia, severe acute respiratory syndrome, \n",
    "kidney failure and even death.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ucQNOFaLW1fu"
   },
   "outputs": [],
   "source": [
    "speech_four ='''Cricket is a sport. \n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1WTGTULem0a",
    "outputId": "9df57776-91ff-49e0-f7b7-c50843798cad",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/purnaperamune/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /Users/purnaperamune/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/purnaperamune/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/purnaperamune/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer\n",
    "import numpy as np\n",
    "import numpy.linalg as LA\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import word_tokenize,pos_tag\n",
    "from nltk.stem import PorterStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mNbXMb7CDXV9"
   },
   "outputs": [],
   "source": [
    "\n",
    "en_stopwords = stopwords.words('english')\n",
    "def remove_stopwords(text):\n",
    "    result = []\n",
    "    for token in text:\n",
    "        if token not in en_stopwords:\n",
    "            result.append(token)\n",
    "            \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "4rdPDLOhDweu"
   },
   "outputs": [],
   "source": [
    "def remove_punct(text):\n",
    "    \n",
    "    tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "    lst=tokenizer.tokenize(' '.join(text))\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "_JJe-ZsND2se"
   },
   "outputs": [],
   "source": [
    "def lemmatization(text):\n",
    "    \n",
    "    result=[]\n",
    "    wordnet = WordNetLemmatizer()\n",
    "    for token,tag in pos_tag(text):\n",
    "        pos=tag[0].lower()\n",
    "        \n",
    "        if pos not in ['a', 'r', 'n', 'v']:\n",
    "            pos='n'\n",
    "            \n",
    "        result.append(wordnet.lemmatize(token,pos))\n",
    "    \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "6AmC1ufKTbH_"
   },
   "outputs": [],
   "source": [
    "def getstring(txt_lst):\n",
    "  wrd = \"\"\n",
    "  for i in txt_lst:\n",
    "    wrd  = wrd+\" \"+i\n",
    "  return wrd.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "FPv68Q4MEAkU"
   },
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "  txt = remove_whitespace(text).lower()\n",
    "  txt = tokenization(txt)\n",
    "  txt = remove_stopwords(txt)\n",
    "  txt = remove_punct(txt)\n",
    "  txt = lemmatization(txt)\n",
    "  return getstring(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DUavkp5TEzuf"
   },
   "outputs": [],
   "source": [
    "s1 = preprocessing(speech_one)\n",
    "s2 = preprocessing(speech_two)\n",
    "s3 = preprocessing(speech_three)\n",
    "s4 = preprocessing(speech_four)\n",
    "m_wrds = preprocessing(Medical_sector_words_lest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "5srnjq_GfTDX"
   },
   "outputs": [],
   "source": [
    "train = [m_wrds]\n",
    "test = [s1,s2,s3,s4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "IE9OuftWfm1B"
   },
   "outputs": [],
   "source": [
    "tfidfvectorizer = TfidfVectorizer(analyzer='word',stop_words= 'english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "533wHVYrfqP5"
   },
   "outputs": [],
   "source": [
    "tfidf_wm = tfidfvectorizer.fit_transform(train)\n",
    "tfidf_wm_test = tfidfvectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "XFz87uAijcx3"
   },
   "outputs": [],
   "source": [
    "cx = lambda a, b : round(np.inner(a, b)/(LA.norm(a)*LA.norm(b)), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_AAvgMjBVKhf",
    "outputId": "a69b4b43-ab21-4b8b-f4fd-88cbcc3fccc1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.047"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cx(tfidf_wm.toarray()[0],tfidf_wm_test.toarray()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "6YdIsTsni9C8"
   },
   "outputs": [],
   "source": [
    "similarity_1 = cx(tfidf_wm_test.toarray()[0],tfidf_wm.toarray()[0])\n",
    "similarity_2 = cx(tfidf_wm.toarray()[0],tfidf_wm_test.toarray()[1])\n",
    "similarity_3 = cx(tfidf_wm.toarray()[0],tfidf_wm_test.toarray()[2])\n",
    "similarity_4 = cx(tfidf_wm.toarray()[0],tfidf_wm_test.toarray()[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wy73MkCc2Qcc",
    "outputId": "b0a2daf3-06ae-4635-aa1c-7b5fafe4c489",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simalarity of Speech 1 to medical sector is 0.047\n",
      "Simalarity of Speech 2 to medical sector is 0.057\n",
      "Simalarity of Speech 3 to medical sector is 0.052\n",
      "Simalarity of Speech 4 to medical sector is 0.007\n"
     ]
    }
   ],
   "source": [
    "print('Simalarity of Speech 1 to medical sector is '+ str(similarity_1))\n",
    "print('Simalarity of Speech 2 to medical sector is '+ str(similarity_2))\n",
    "print('Simalarity of Speech 3 to medical sector is '+ str(similarity_3))\n",
    "print('Simalarity of Speech 4 to medical sector is '+ str(similarity_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "Y0gJuH4VCKdf"
   },
   "outputs": [],
   "source": [
    "#more similarity mean more relevance to medical. \n",
    "#so speech 4 is less similar or not relevance to medical"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Check_ relevance .ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
